{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90058632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "from power_ratings.featurizers import FeatureBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install nb-black\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b118b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some assumptions gleaned from prior data analysis\n",
    "\n",
    "# an overtime adds about 7-9 points on average\n",
    "OVERTIME_SCORE_BONUS = 7.4\n",
    "\n",
    "SEASONS = list(range(2000, 2023))\n",
    "# SEASONS = (2022,)\n",
    "\n",
    "DATA_PREFIX = \"W\"\n",
    "\n",
    "# if we want to use predetermined values instead of distributions,\n",
    "# we can set this flag\n",
    "USE_PREDETERMINED = True\n",
    "\n",
    "if DATA_PREFIX == \"M\":\n",
    "    pre_scaler = 0.59\n",
    "    pre_base = 69.5\n",
    "else:\n",
    "    pre_scaler = 0.79\n",
    "    pre_base = 64.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in game data, team names, and previously-calculated Elo scores for comparison\n",
    "\n",
    "feature_base = FeatureBase(prefix=DATA_PREFIX)\n",
    "games_df = pd.read_csv(f\"./data/{DATA_PREFIX}RegularSeasonCompactResults.csv\")\n",
    "teamnames = pd.read_csv(f\"data/{DATA_PREFIX}Teams.csv\")\n",
    "elo_df = feature_base.elo_features.reset_index()\n",
    "elo_df[\"elo\"] = elo_df[\"elo_32_day0_True\"]\n",
    "\n",
    "games_df = games_df[games_df.Season.isin(SEASONS)]\n",
    "print(games_df.shape)\n",
    "\n",
    "games_df = pd.merge(\n",
    "    games_df,\n",
    "    elo_df,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Season\", \"WTeamID\"],\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    ")\n",
    "games_df[\"WTeamID\"] = games_df[[\"Season\", \"WTeamID\"]].apply(\n",
    "    lambda x: \"_\".join([str(v) for v in x]), axis=1\n",
    ")\n",
    "games_df = games_df.rename(\n",
    "    columns={\n",
    "        \"elo\": \"T1elo\",\n",
    "        \"WTeamID\": \"T1TeamID\",\n",
    "        \"WScore\": \"T1Score\",\n",
    "        \"WLoc\": \"T1Loc\",\n",
    "    }\n",
    ").drop(columns=[\"TeamID\"])\n",
    "games_df[\"T1Wins\"] = 1.0\n",
    "\n",
    "games_df[\"T1Home\"] = games_df.T1Loc.apply(lambda x: 1 if x == \"H\" else 0)\n",
    "t2home = games_df.T1Loc.apply(lambda x: 1 if x == \"A\" else 0).values\n",
    "\n",
    "games_df = pd.merge(\n",
    "    games_df,\n",
    "    elo_df,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Season\", \"LTeamID\"],\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    ")\n",
    "games_df[\"LTeamID\"] = games_df[[\"Season\", \"LTeamID\"]].apply(\n",
    "    lambda x: \"_\".join([str(v) for v in x]), axis=1\n",
    ")\n",
    "games_df = games_df.rename(\n",
    "    columns={\n",
    "        \"elo\": \"T2elo\",\n",
    "        \"LTeamID\": \"T2TeamID\",\n",
    "        \"LScore\": \"T2Score\",\n",
    "    }\n",
    ").drop(columns=[\"TeamID\", \"DayNum\"])\n",
    "\n",
    "renames = {c: \"T2\" + c[2:] for c in games_df.columns if c[:2] == \"T1\" and c != \"T1Home\"}\n",
    "renames.update({c: \"T1\" + c[2:] for c in games_df.columns if c[:2] == \"T2\"})\n",
    "inv_games_df = games_df.copy().rename(columns=renames)\n",
    "inv_games_df[\"T1Wins\"] = 0.0\n",
    "inv_games_df[\"T1Home\"] = t2home\n",
    "games_df = (\n",
    "    pd.concat([games_df, inv_games_df])\n",
    "    .drop(columns=[\"T2Loc\", \"T2Score\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "games_df = games_df[games_df.NumOT < 2]\n",
    "games_df[\"T1Score\"] = games_df[[\"T1Score\", \"NumOT\"]].apply(\n",
    "    lambda x: x[0] - OVERTIME_SCORE_BONUS * x[1], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbf142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfce6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(games_df):\n",
    "    mean_game_score = int(games_df[games_df.NumOT == 0].T1Score.mean())\n",
    "\n",
    "    # factorize turns our team IDs into sequential ints like [0, 1, 2, ...]\n",
    "    t1_idx, teams = pd.factorize(games_df[\"T1TeamID\"], sort=True)\n",
    "    t2_idx, _ = pd.factorize(games_df[\"T2TeamID\"], sort=True)\n",
    "    game_ids = games_df.index.values\n",
    "\n",
    "    # shape of this is taken from Rugby Analytics example here:\n",
    "    # https://oriolabril.github.io/oriol_unraveled/python/arviz/pymc3/xarray/2020/09/22/pymc3-arviz.html\n",
    "    coords = {\"team\": teams, \"game\": game_ids}\n",
    "\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # constant data\n",
    "        t1 = pm.Data(\"t1\", t1_idx, dims=\"game\")\n",
    "        t2 = pm.Data(\"t2\", t2_idx, dims=\"game\")\n",
    "\n",
    "        #     off_sigma = pm.Uniform(\"off_sigma\", lower=5, upper=15)\n",
    "        #     def_sigma = pm.Uniform(\"def_sigma\", lower=5, upper=15)\n",
    "        off_sigma, def_sigma = 10, 10\n",
    "\n",
    "        # team-specific model parameters\n",
    "        offense = pm.Normal(\"offense\", mu=50, sigma=off_sigma, dims=\"team\")\n",
    "        defense = pm.Normal(\"defense\", mu=50, sigma=def_sigma, dims=\"team\")\n",
    "\n",
    "        if not USE_PREDETERMINED:\n",
    "            scaler = pm.Normal(\"scaler\", mu=0.5, sigma=0.3)\n",
    "            base = pm.Normal(\"base\", mu=mean_game_score - 5, sigma=2)\n",
    "        else:\n",
    "            scaler = pre_scaler\n",
    "            base = pre_base\n",
    "\n",
    "        # game win parameters\n",
    "        #     x0 = pm.Normal(\"t1off_minus_t2def_weight\", mu=0.1, sigma=0.05)\n",
    "        #     x1 = pm.Normal(\"t2off_minus_t1def_weight\", mu=0.1, sigma=0.05)\n",
    "\n",
    "        t1_score = pm.Deterministic(\n",
    "            \"score\", (offense[t1_idx] - defense[t2_idx]) * scaler + base\n",
    "        )\n",
    "        #     t1_win_prob = pm.Deterministic(\n",
    "        #         \"win_prob\",\n",
    "        #         pm.invlogit(\n",
    "        #             x0 * (offense[t1_idx] - defense[t2_idx])\n",
    "        #             - x1 * (offense[t2_idx] - defense[t1_idx])\n",
    "        #         ),\n",
    "        #     )\n",
    "\n",
    "        # likelihood of observed data\n",
    "        t1_pts = pm.Normal(\n",
    "            \"t1_points\", mu=t1_score, sigma=5, observed=games_df.T1Score, dims=(\"game\")\n",
    "        )\n",
    "        #     t1_wins = pm.Bernoulli(\"t1_wins\", p=t1_win_prob, observed=games_df.T1Wins)\n",
    "\n",
    "        trace = pm.sample(\n",
    "            1000,\n",
    "            tune=1000,\n",
    "            cores=4,\n",
    "            return_inferencedata=True,\n",
    "            target_accept=0.9,\n",
    "        )\n",
    "    return trace\n",
    "\n",
    "\n",
    "def get_ratings_df(trace_hdi):\n",
    "    ratings_df = pd.DataFrame(\n",
    "        list(\n",
    "            zip(\n",
    "                trace_hdi[\"offense\"].team.values,\n",
    "                trace_hdi[\"offense\"].values[:, 0],\n",
    "                trace_hdi[\"defense\"].values[:, 0],\n",
    "            )\n",
    "        ),\n",
    "        columns=[\"FullTeamID\", \"OffensiveRating\", \"DefensiveRating\"],\n",
    "    )\n",
    "    ratings_df[\"Season\"] = ratings_df[\"FullTeamID\"].apply(\n",
    "        lambda x: int(x.split(\"_\")[0])\n",
    "    )\n",
    "    ratings_df[\"TeamID\"] = ratings_df[\"FullTeamID\"].apply(\n",
    "        lambda x: int(x.split(\"_\")[1])\n",
    "    )\n",
    "\n",
    "    return ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ratings_df = pd.DataFrame()\n",
    "for year in SEASONS:\n",
    "    if year in games_df.Season.unique():\n",
    "        # process each year with past years to lower inter-year variance\n",
    "        trace = train_model(\n",
    "            games_df[games_df.Season.isin((year - 2, year - 1, year))].copy()\n",
    "        )\n",
    "        trace_hdi = az.hdi(trace)\n",
    "        ratings_df = get_ratings_df(trace_hdi)\n",
    "        ratings_df = ratings_df[ratings_df.Season == year]\n",
    "        full_ratings_df = pd.concat([full_ratings_df, ratings_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40311a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.plot_trace(\n",
    "#     trace,\n",
    "#     var_names=[\n",
    "#         \"scaler\",\n",
    "#         \"base\",\n",
    "#         #         \"t1off_minus_t2def_weight\",\n",
    "#         #         \"t2off_minus_t1def_weight\",\n",
    "#     ],\n",
    "#     compact=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3813364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.summary(trace, kind=\"diagnostics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.groupby(\"Season\").median()[\"T1Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81810efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ratings_df.groupby(\"Season\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5bcff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423fadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_ratings_df = full_ratings_df.groupby(\"FullTeamID\").median().reset_index()\n",
    "joined = pd.merge(\n",
    "    full_ratings_df,\n",
    "    elo_df,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Season\", \"TeamID\"],\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    ")\n",
    "joined = pd.merge(\n",
    "    joined, teamnames, how=\"left\", left_on=[\"TeamID\"], right_on=[\"TeamID\"]\n",
    ")\n",
    "\n",
    "joined = joined.rename(\n",
    "    columns={\"elo_32_day30_True\": \"EloWithScore\", \"elo_32_day0_False\": \"EloWinLoss\"}\n",
    ")\n",
    "joined[\"CombinedRating\"] = joined[\"OffensiveRating\"] + joined[\"DefensiveRating\"]\n",
    "output_df = joined[\n",
    "    [\n",
    "        \"Season\",\n",
    "        \"TeamName\",\n",
    "        \"CombinedRating\",\n",
    "        \"OffensiveRating\",\n",
    "        \"DefensiveRating\",\n",
    "        \"EloWithScore\",\n",
    "        \"EloWinLoss\",\n",
    "    ]\n",
    "].copy()\n",
    "float_cols = output_df.select_dtypes(float).columns\n",
    "for fc in float_cols:\n",
    "    output_df[fc] = output_df[fc].apply(np.round, args=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.groupby(\"Season\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e4192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.sort_values([\"Season\", \"CombinedRating\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(f\"output/{DATA_PREFIX}_data.csv\", index=False)\n",
    "joined.to_csv(f\"data/{DATA_PREFIX}features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56056812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_sub = joined[~joined.adj_o.isna()]\n",
    "# print(f\"offensive KT: {kendalltau(joined_sub.adj_o, joined_sub.OffensiveRating)}\")\n",
    "# print(f\"defensive KT: {kendalltau(joined_sub.adj_d, joined_sub.DefensiveRating)}\")\n",
    "# print(f\"rank to off KT: {kendalltau(joined_sub['rank'], joined_sub.OffensiveRating)}\")\n",
    "# print(f\"rank to def KT: {kendalltau(joined_sub['rank'], joined_sub.DefensiveRating)}\")\n",
    "# print(\n",
    "#     f\"rank to summed KT: {kendalltau(joined_sub['rank'], joined_sub.DefensiveRating+joined_sub.OffensiveRating)}\"\n",
    "# )\n",
    "# print(\n",
    "#     f\"elo to summed KT: {kendalltau(joined_sub['elo_16_day0_True'], joined_sub.DefensiveRating+joined_sub.OffensiveRating)}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad485dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
