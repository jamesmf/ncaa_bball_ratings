{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90058632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as T\n",
    "import os\n",
    "\n",
    "os.environ[\"ROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]=\"python\"\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "from scipy.stats import linregress, kendalltau, spearmanr\n",
    "from scipy.sparse import csr\n",
    "import mlflow\n",
    "\n",
    "from power_ratings.featurizers import FeatureBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14673ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install nb-black\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b118b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some assumptions gleaned from prior data analysis\n",
    "\n",
    "# an overtime adds about 7-9 points on average\n",
    "OVERTIME_SCORE_BONUS = 7.4\n",
    "\n",
    "SEASONS = list(range(2000, 2023))\n",
    "# SEASONS = (2022,)\n",
    "\n",
    "DATA_PREFIX = \"M\"\n",
    "\n",
    "# if we want to use predetermined values instead of distributions,\n",
    "# we can set this flag\n",
    "USE_PREDETERMINED = True\n",
    "\n",
    "if DATA_PREFIX == \"M\":\n",
    "    pre_scaler = 0.59\n",
    "    pre_base = 69.5\n",
    "else:\n",
    "    pre_scaler = 0.79\n",
    "    pre_base = 64.0\n",
    "\n",
    "params = {\n",
    "    \"overtime_score_discount\": OVERTIME_SCORE_BONUS,\n",
    "    \"season\": f\"[{','.join([str(i) for i in SEASONS])}]\",\n",
    "    \"data_prefix\": DATA_PREFIX,\n",
    "    \"use_predetermined\": USE_PREDETERMINED,\n",
    "    \"pre_scaler\": pre_scaler,\n",
    "    \"pre_base\": pre_base,\n",
    "}\n",
    "\n",
    "mlflow.set_experiment(\"feature-generation-2022\")\n",
    "mlflow.log_params({k: str(v) for k, v in params.items()})\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in game data, team names, and previously-calculated Elo scores for comparison\n",
    "\n",
    "feature_base = FeatureBase(prefix=DATA_PREFIX)\n",
    "games_df = pd.read_csv(f\"./data/{DATA_PREFIX}RegularSeasonCompactResults.csv\")\n",
    "teamnames = pd.read_csv(f\"data/{DATA_PREFIX}Teams.csv\")\n",
    "elo_df = feature_base.elo_features.reset_index()\n",
    "elo_df[\"elo\"] = elo_df[\"elo_32_day0_True\"]\n",
    "\n",
    "games_df = games_df[games_df.Season.isin(SEASONS)]\n",
    "print(games_df.shape)\n",
    "\n",
    "games_df = pd.merge(\n",
    "    games_df,\n",
    "    elo_df,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Season\", \"WTeamID\"],\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    ")\n",
    "games_df[\"WTeamID\"] = games_df[[\"Season\", \"WTeamID\"]].apply(\n",
    "    lambda x: \"_\".join([str(v) for v in x]), axis=1\n",
    ")\n",
    "games_df = games_df.rename(\n",
    "    columns={\n",
    "        \"elo\": \"T1elo\",\n",
    "        \"WTeamID\": \"T1TeamID\",\n",
    "        \"WScore\": \"T1Score\",\n",
    "        \"WLoc\": \"T1Loc\",\n",
    "    }\n",
    ").drop(columns=[\"TeamID\"])\n",
    "games_df[\"T1Wins\"] = 1.0\n",
    "\n",
    "games_df[\"T1Home\"] = games_df.T1Loc.apply(lambda x: 1 if x == \"H\" else 0)\n",
    "t2home = games_df.T1Loc.apply(lambda x: 1 if x == \"A\" else 0).values\n",
    "\n",
    "games_df = pd.merge(\n",
    "    games_df,\n",
    "    elo_df,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Season\", \"LTeamID\"],\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    ")\n",
    "games_df[\"LTeamID\"] = games_df[[\"Season\", \"LTeamID\"]].apply(\n",
    "    lambda x: \"_\".join([str(v) for v in x]), axis=1\n",
    ")\n",
    "games_df = games_df.rename(\n",
    "    columns={\n",
    "        \"elo\": \"T2elo\",\n",
    "        \"LTeamID\": \"T2TeamID\",\n",
    "        \"LScore\": \"T2Score\",\n",
    "    }\n",
    ").drop(columns=[\"TeamID\", \"DayNum\"])\n",
    "\n",
    "renames = {c: \"T2\" + c[2:] for c in games_df.columns if c[:2] == \"T1\" and c != \"T1Home\"}\n",
    "renames.update({c: \"T1\" + c[2:] for c in games_df.columns if c[:2] == \"T2\"})\n",
    "inv_games_df = games_df.copy().rename(columns=renames)\n",
    "inv_games_df[\"T1Wins\"] = 0.0\n",
    "inv_games_df[\"T1Home\"] = t2home\n",
    "games_df = (\n",
    "    pd.concat([games_df, inv_games_df])\n",
    "    .drop(columns=[\"T2Loc\", \"T2Score\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "games_df = games_df[games_df.NumOT < 2]\n",
    "games_df[\"T1Score\"] = games_df[[\"T1Score\", \"NumOT\"]].apply(\n",
    "    lambda x: x[0] - OVERTIME_SCORE_BONUS * x[1], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbf142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfce6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(games_df):\n",
    "    mean_game_score = int(games_df[games_df.NumOT == 0].T1Score.mean())\n",
    "\n",
    "    # factorize turns our team IDs into sequential ints like [0, 1, 2, ...]\n",
    "    t1_idx, teams = pd.factorize(games_df[\"T1TeamID\"], sort=True)\n",
    "    t2_idx, _ = pd.factorize(games_df[\"T2TeamID\"], sort=True)\n",
    "    game_ids = games_df.index.values\n",
    "\n",
    "    # shape of this is taken from Rugby Analytics example here:\n",
    "    # https://oriolabril.github.io/oriol_unraveled/python/arviz/pymc3/xarray/2020/09/22/pymc3-arviz.html\n",
    "    coords = {\"team\": teams, \"game\": game_ids}\n",
    "\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # constant data\n",
    "        t1 = pm.Data(\"t1\", t1_idx, dims=\"game\", mutable=True)\n",
    "        t2 = pm.Data(\"t2\", t2_idx, dims=\"game\", mutable=True)\n",
    "\n",
    "        #     off_sigma = pm.Uniform(\"off_sigma\", lower=5, upper=15)\n",
    "        #     def_sigma = pm.Uniform(\"def_sigma\", lower=5, upper=15)\n",
    "        off_sigma, def_sigma = 10, 10\n",
    "\n",
    "        # team-specific model parameters\n",
    "        offense = pm.Normal(\"offense\", mu=50, sigma=off_sigma, dims=\"team\")\n",
    "        defense = pm.Normal(\"defense\", mu=50, sigma=def_sigma, dims=\"team\")\n",
    "        team_score_sigma = pm.Normal(\"team_score_sigma\", mu=9, sigma=2, dims=\"team\")\n",
    "\n",
    "        if not USE_PREDETERMINED:\n",
    "            scaler = pm.Normal(\"scaler\", mu=0.5, sigma=0.3)\n",
    "            base = pm.Normal(\"base\", mu=mean_game_score - 5, sigma=2)\n",
    "        else:\n",
    "            scaler = pre_scaler\n",
    "            base = pre_base\n",
    "\n",
    "        # game win parameters\n",
    "        #         x0 = pm.Normal(\"t1off_minus_t2def_weight\", mu=0.1, sigma=0.05)\n",
    "        #         x1 = pm.Normal(\"t2off_minus_t1def_weight\", mu=0.1, sigma=0.05)\n",
    "\n",
    "        t1_score = pm.Deterministic(\n",
    "            \"score\", (offense[t1_idx] - defense[t2_idx]) * scaler + base\n",
    "        )\n",
    "        #         t1_win_prob = pm.Deterministic(\n",
    "        #             \"win_prob\",\n",
    "        #             pm.invlogit(\n",
    "        #                 x0 * (offense[t1_idx] - defense[t2_idx])\n",
    "        #                 - x1 * (offense[t2_idx] - defense[t1_idx])\n",
    "        #             ),\n",
    "        #         )\n",
    "\n",
    "        # likelihood of observed data\n",
    "        t1_pts = pm.Normal(\n",
    "            \"t1_points\",\n",
    "            mu=t1_score,\n",
    "            sigma=team_score_sigma[t1_idx],\n",
    "            observed=games_df.T1Score,\n",
    "            dims=(\"game\"),\n",
    "        )\n",
    "        #         t1_wins = pm.Bernoulli(\"t1_wins\", p=t1_win_prob, observed=games_df.T1Wins)\n",
    "\n",
    "        trace = pm.sample(\n",
    "            750,\n",
    "            tune=750,\n",
    "            cores=10,\n",
    "            return_inferencedata=True,\n",
    "            target_accept=0.9,\n",
    "        )\n",
    "    return trace\n",
    "\n",
    "\n",
    "def get_ratings_df(trace):\n",
    "    trace_hdi = az.hdi(trace, hdi_prob=0.9)\n",
    "    #     trace_hdi_tight = az.hdi(trace, hdi_prob=0.5)\n",
    "    ratings_df = pd.DataFrame(\n",
    "        list(\n",
    "            zip(\n",
    "                trace_hdi[\"offense\"].team.values,\n",
    "                trace_hdi[\"offense\"].values[:, 0],\n",
    "                trace_hdi[\"offense\"].values[:, 1],\n",
    "                trace_hdi[\"defense\"].values[:, 0],\n",
    "                trace_hdi[\"defense\"].values[:, 1],\n",
    "                trace_hdi[\"team_score_sigma\"].values[:, 0],\n",
    "                trace_hdi[\"team_score_sigma\"].values[:, 1],\n",
    "            )\n",
    "        ),\n",
    "        columns=[\n",
    "            \"FullTeamID\",\n",
    "            \"OffensiveRatingLB\",\n",
    "            \"OffensiveRatingUB\",\n",
    "            \"DefensiveRatingLB\",\n",
    "            \"DefensiveRatingUB\",\n",
    "            \"ScoreVarianceLB\",\n",
    "            \"ScoreVarianceUB\",\n",
    "        ],\n",
    "    )\n",
    "    ratings_df[\"OffensiveRating\"] = (\n",
    "        trace_hdi[\"offense\"].values[:, 0] + trace_hdi[\"offense\"].values[:, 1]\n",
    "    ) / 2\n",
    "    ratings_df[\"DefensiveRating\"] = (\n",
    "        trace_hdi[\"defense\"].values[:, 0] + trace_hdi[\"defense\"].values[:, 1]\n",
    "    ) / 2\n",
    "    ratings_df[\"ScoreVariance\"] = (\n",
    "        trace_hdi[\"team_score_sigma\"].values[:, 0]\n",
    "        + trace_hdi[\"team_score_sigma\"].values[:, 1]\n",
    "    ) / 2\n",
    "\n",
    "    ratings_df[\"Season\"] = ratings_df[\"FullTeamID\"].apply(\n",
    "        lambda x: int(x.split(\"_\")[0])\n",
    "    )\n",
    "    ratings_df[\"TeamID\"] = ratings_df[\"FullTeamID\"].apply(\n",
    "        lambda x: int(x.split(\"_\")[1])\n",
    "    )\n",
    "\n",
    "    return ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3b0df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_ratings_df = pd.DataFrame()\n",
    "for year in SEASONS:\n",
    "    if year in games_df.Season.unique():\n",
    "        # process each year with past years to lower inter-year variance\n",
    "        trace = train_model(\n",
    "            games_df[games_df.Season.isin((year - 3, year - 2, year - 1, year))].copy()\n",
    "        )\n",
    "        ratings_df = get_ratings_df(trace)\n",
    "        ratings_df = ratings_df[ratings_df.Season == year]\n",
    "        full_ratings_df = pd.concat([full_ratings_df, ratings_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40311a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# coords = {\"team\": [\"2003_3102\"]}\n",
    "az.plot_trace(\n",
    "    trace,\n",
    "    var_names=[\n",
    "        \"offense\",\n",
    "        #         \"team_score_sigma\"\n",
    "        #         \"base\",\n",
    "        #         \"t1off_minus_t2def_weight\",\n",
    "        #         \"t2off_minus_t1def_weight\",\n",
    "    ],\n",
    "    #     coords=coords,\n",
    "    compact=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9195ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frdf = get_ratings_df(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0859187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3813364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.summary(trace, kind=\"diagnostics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81810efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ratings_df.groupby(\"Season\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5bcff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423fadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_ratings_df = full_ratings_df.groupby(\"FullTeamID\").median().reset_index()\n",
    "joined = pd.merge(\n",
    "    full_ratings_df,\n",
    "    elo_df,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Season\", \"TeamID\"],\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    ")\n",
    "joined = pd.merge(\n",
    "    joined, teamnames, how=\"left\", left_on=[\"TeamID\"], right_on=[\"TeamID\"]\n",
    ")\n",
    "\n",
    "joined = joined.rename(\n",
    "    columns={\"elo_32_day30_True\": \"EloWithScore\", \"elo_32_day0_False\": \"EloWinLoss\"}\n",
    ")\n",
    "joined[\"CombinedRating\"] = joined[\"OffensiveRating\"] + joined[\"DefensiveRating\"]\n",
    "output_df = joined[\n",
    "    [\n",
    "        \"Season\",\n",
    "        \"TeamName\",\n",
    "        \"CombinedRating\",\n",
    "        \"OffensiveRating\",\n",
    "        \"DefensiveRating\",\n",
    "        \"ScoreVariance\",\n",
    "        \"EloWithScore\",\n",
    "        \"EloWinLoss\",\n",
    "        \"OffensiveRatingLB\",\n",
    "        \"OffensiveRatingUB\",\n",
    "        \"DefensiveRatingLB\",\n",
    "        \"DefensiveRatingUB\",\n",
    "        \"ScoreVarianceLB\",\n",
    "        \"ScoreVarianceUB\",\n",
    "        \"TeamID\",\n",
    "    ]\n",
    "].copy()\n",
    "float_cols = output_df.select_dtypes(float).columns\n",
    "for fc in float_cols:\n",
    "    output_df[fc] = output_df[fc].apply(np.round, args=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.groupby(\"Season\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e4192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.sort_values([\"Season\", \"CombinedRating\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(f\"output/{DATA_PREFIX}_data_interim.csv\", index=False)\n",
    "joined.to_csv(f\"data/{DATA_PREFIX}features_interim.csv\", index=False)\n",
    "\n",
    "mlflow.log_artifact(f\"output/{DATA_PREFIX}_data_interim.csv\")\n",
    "mlflow.log_artifact(f\"data/{DATA_PREFIX}features_interim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56056812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_sub = joined[~joined.adj_o.isna()]\n",
    "# print(f\"offensive KT: {kendalltau(joined_sub.adj_o, joined_sub.OffensiveRating)}\")\n",
    "# print(f\"defensive KT: {kendalltau(joined_sub.adj_d, joined_sub.DefensiveRating)}\")\n",
    "# print(f\"rank to off KT: {kendalltau(joined_sub['rank'], joined_sub.OffensiveRating)}\")\n",
    "# print(f\"rank to def KT: {kendalltau(joined_sub['rank'], joined_sub.DefensiveRating)}\")\n",
    "# print(\n",
    "#     f\"rank to summed KT: {kendalltau(joined_sub['rank'], joined_sub.DefensiveRating+joined_sub.OffensiveRating)}\"\n",
    "# )\n",
    "# print(\n",
    "#     f\"elo to summed KT: {kendalltau(joined_sub['elo_16_day0_True'], joined_sub.DefensiveRating+joined_sub.OffensiveRating)}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad485dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Caclulate efficiency features\n",
    "####################################\n",
    "from power_ratings.tournament_dataset import df_rename, feature_rename\n",
    "\n",
    "detailed_df = pd.read_csv(f\"./data/{DATA_PREFIX}RegularSeasonDetailedResults.csv\")\n",
    "existing_feature_df = pd.read_csv(\n",
    "    f\"output/{DATA_PREFIX}_data_interim.csv\",\n",
    "    #     usecols=[\"Season\", \"TeamID\", \"DefensiveRating\", \"OffensiveRating\"],\n",
    ").set_index([\"Season\", \"TeamID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07411cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_eff = pd.merge(\n",
    "    detailed_df,\n",
    "    feature_rename(existing_feature_df, \"W\"),\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Season\", \"WTeamID\"],\n",
    "    right_index=True\n",
    ")\n",
    "df_for_eff = pd.merge(\n",
    "    df_for_eff,\n",
    "    feature_rename(existing_feature_df, \"L\"),\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Season\", \"LTeamID\"],\n",
    "    right_index=True\n",
    ")\n",
    "pos = df_rename(df_for_eff, \"W\", \"L\")\n",
    "neg = df_rename(df_for_eff, \"L\", \"W\")\n",
    "df_for_eff = pd.concat((pos, neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b23a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_eff[\"ApproxPoss\"] = df_for_eff.apply(\n",
    "    lambda x: (\n",
    "        x[\"T1FGA\"]\n",
    "        - x[\"T1OR\"]\n",
    "        + x[\"T1TO\"]\n",
    "        + 0.475 * x[\"T1FTA\"]\n",
    "        + x[\"T2FGA\"]\n",
    "        - x[\"T2OR\"]\n",
    "        + x[\"T2TO\"]\n",
    "        + 0.475 * x[\"T2FTA\"]\n",
    "    )\n",
    "    / 2,\n",
    "    axis=1,\n",
    ")\n",
    "df_for_eff[\"PossAdjForOT\"] = df_for_eff.apply(\n",
    "    lambda x: x[\"ApproxPoss\"] - 7.5 * x[\"NumOT\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_for_eff[\"T1PtsPerPossEstimate\"] = df_for_eff.apply(\n",
    "    lambda x: x[\"T1Score\"] / x[\"ApproxPoss\"] ,\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_eff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f68230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.sparse import csr\n",
    "\n",
    "team_map = {}\n",
    "for team in (\n",
    "    df_for_eff[[\"Season\", \"T1TeamID\"]]\n",
    "    .apply(lambda x: f\"{x[0]}_{x[1]}\", axis=1)\n",
    "    .unique()\n",
    "):\n",
    "    team_map[team] = len(team_map)\n",
    "\n",
    "\n",
    "def create_pace_feature(df: pd.DataFrame, team_id_map: T.Dict[int, int]):\n",
    "    data, rows, cols, y = [], [], [], []\n",
    "    n = 0\n",
    "    for season, t1, t2, poss_adj in df[\n",
    "        [\"Season\", \"T1TeamID\", \"T2TeamID\", \"PossAdjForOT\"]\n",
    "    ].values:\n",
    "        ind1 = team_id_map[f\"{int(season)}_{int(t1)}\"]\n",
    "        ind2 = team_id_map[f\"{int(season)}_{int(t2)}\"]\n",
    "        rows.extend([n, n])\n",
    "        cols.extend([ind1, ind2])\n",
    "        data.extend([1, 1])\n",
    "        y.append(poss_adj)\n",
    "        n += 1\n",
    "    x = csr.csr_matrix((data, (rows, cols)), shape=(n, len(team_id_map)))\n",
    "    lr = LinearRegression().fit(x, y)\n",
    "\n",
    "    inv = {v: k for k, v in team_id_map.items()}\n",
    "    pace_data = []\n",
    "    for n, coef in enumerate(lr.coef_):\n",
    "        season_team_id = inv[n]\n",
    "        season, team_id = [int(i) for i in season_team_id.split(\"_\")]\n",
    "        pace_data.append([season, team_id, np.round(lr.intercept_ + coef, 1)])\n",
    "    return pd.DataFrame(pace_data, columns=[\"Season\", \"TeamID\", \"TempoEstimate\"])\n",
    "\n",
    "\n",
    "def create_est_pts_per_poss_feature(df: pd.DataFrame, team_id_map: T.Dict[int, int]):\n",
    "    data, rows, cols, y = [], [], [], []\n",
    "    n_teams = len(team_id_map)\n",
    "    n = 0\n",
    "    for season, t1, t2def, pts_per_estimate in df[\n",
    "        [\"Season\", \"T1TeamID\", \"T2DefensiveRating\", \"T1PtsPerPossEstimate\"]\n",
    "    ].values:\n",
    "        ind1 = team_id_map[f\"{int(season)}_{int(t1)}\"]\n",
    "        rows.extend([n, n])\n",
    "        cols.extend([ind1, n_teams])\n",
    "        data.extend([1, t2def])\n",
    "        y.append(pts_per_estimate)\n",
    "        n += 1\n",
    "    x = csr.csr_matrix((data, (rows, cols)), shape=(n, n_teams + 1))\n",
    "    lr = LinearRegression().fit(x, y)\n",
    "    preds = lr.predict(x)\n",
    "    r2 = linregress(y, preds).rvalue ** 2\n",
    "    kt = kendalltau(y, preds)[0]\n",
    "    print(lr.intercept_, lr.coef_[-1], r2, kt)\n",
    "\n",
    "    inv = {v: k for k, v in team_id_map.items()}\n",
    "    pace_data = []\n",
    "    for n, coef in enumerate(lr.coef_[:-1]):\n",
    "        season_team_id = inv[n]\n",
    "        season, team_id = [int(i) for i in season_team_id.split(\"_\")]\n",
    "        pace_data.append([season, team_id, np.round(lr.intercept_ + coef, 2)])\n",
    "    return pd.DataFrame(\n",
    "        pace_data, columns=[\"Season\", \"TeamID\", \"PossessionEfficiencyFactor\"]\n",
    "    )\n",
    "\n",
    "\n",
    "pace_df = create_pace_feature(df_for_eff, team_map)\n",
    "pts_per_poss_df = create_est_pts_per_poss_feature(df_for_eff, team_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77febd38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5fe21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = pd.merge(\n",
    "    existing_feature_df,\n",
    "    pts_per_poss_df,\n",
    "    how=\"left\",\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    "    left_index=True,\n",
    "    suffixes=('_old', '')\n",
    ").set_index([\"Season\", \"TeamID\"])\n",
    "new_features = pd.merge(\n",
    "    new_features,\n",
    "    pace_df,\n",
    "    how=\"left\",\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    "    left_index=True,\n",
    "    suffixes=('_old', '')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6260dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad005540",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features[\n",
    "    [\n",
    "        \"Season\",\n",
    "        \"TeamID\",\n",
    "        \"TeamName\",\n",
    "        \"CombinedRating\",\n",
    "        \"OffensiveRating\",\n",
    "        \"DefensiveRating\",\n",
    "        \"EloWithScore\",\n",
    "        \"EloWinLoss\",\n",
    "        \"PossessionEfficiencyFactor\",\n",
    "        \"TempoEstimate\",\n",
    "        \"ScoreVariance\",\n",
    "        \"OffensiveRatingLB\",\n",
    "        \"DefensiveRatingLB\",\n",
    "        \"OffensiveRatingUB\",\n",
    "        \"DefensiveRatingUB\",\n",
    "    ]\n",
    "].to_csv(f\"output/{DATA_PREFIX}_data_complete.csv\", index=False)\n",
    "\n",
    "mlflow.log_artifact(f\"output/{DATA_PREFIX}_data_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_check = new_features.dropna()\n",
    "print(kendalltau(corr_check.OffensiveRating, corr_check.PossessionEfficiencyFactor))\n",
    "print(spearmanr(corr_check.OffensiveRating, corr_check.PossessionEfficiencyFactor))\n",
    "print(\n",
    "    linregress(corr_check.OffensiveRating, corr_check.PossessionEfficiencyFactor).rvalue\n",
    "    ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeff058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kendalltau(corr_check.OffensiveRating, corr_check.DefensiveRating))\n",
    "print(spearmanr(corr_check.OffensiveRating, corr_check.DefensiveRating))\n",
    "print(linregress(corr_check.OffensiveRating, corr_check.DefensiveRating).rvalue ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df55a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kendalltau(corr_check.DefensiveRating, corr_check.PossessionEfficiencyFactor))\n",
    "print(spearmanr(corr_check.DefensiveRating, corr_check.PossessionEfficiencyFactor))\n",
    "print(\n",
    "    linregress(corr_check.DefensiveRating, corr_check.PossessionEfficiencyFactor).rvalue\n",
    "    ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2d71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c05526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
